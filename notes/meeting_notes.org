#+TODO: TODO(t) | CANCELLED(c) DONE(d)
#+OPTIONS: tasks:todo
* Notes from <2020-11-02 Mon>                                       :ARCHIVE:
** Present at meeting
   - [X] Micah
   - [X] Dan
   - [X] Bruce
** Notes
*** Alignment 8
    - Micah
      - Overall good
**** TODO Action #1 Add explanation for explicit reliability             :#1:
     - But: way I call NPV unreliable
       - the implication of that: unreliable because estimates are imperceise
     - precision of the metric prediction
     - Also:
     #+begin_quote
     I would also change "in this particular industry, NPV is an unrelaible
     predictor of project success" to "in this industry, NPV is an unreliable
     predictor of a project's profits"
     #+end_quote
     - Unreliability
       - Good feature some times too
       - Usually it means that there's a greater upside and downside
       - Makes it sound like a bad thing. Whereas when implicitly unreliable
         might be different
         - Unreliable because it's such a wide range of outcomes
           - broader range = meaning we have less confidence
**** Four way interaction
     - Focus on subcomponents
     - If hypotheses only concern a subset
     - Three way interaction for explicit, and no for implicit
       - implies four-way
     - how much more expensive
       - four way is right way to go, other wise have to predict no effect
     - can specify the interactions
**** TODO Action #2 power analysis                                       :#2:
**** Instructions
     - NPV check
       - Maybe part of experiment
       - On a simple task
       - maybe forcing NPV down their throats
       - But actually ok
*** Aggregation
**** TODO Action #3 Send aggregation analyses                            :#3:
     - Thursday - just about aggregation
      
* Notes from <2020-11-09 Mon>                                       :ARCHIVE:
** Present at meeting
   - [X] Dan
   - [X] Bruce
** Notes
*** Alignment 
    - People have different meanings on what reliable means
    - Clearer now
    - Not everyone will read and understand
**** TODO Action #5 Reanalyse aggregation 4                             :#5:
     - Fix contrasts
     - Try 1 vs 20
     - Try aware vs naive for 20 or last five
     - Try different trends
       - quadratic
       - straight and then linear after half way
*** Aggregation
    - Giving one at a time
    - Expect risk aversion
      - compared to graph
    - One is telling them 20 projects
      - Other one: not
    - When taking one at a time
    - Question: how does degree of risk aversion compare to distribution
    - Effect of trial
      - Compare awareness for trial 20
      - Compare 1 and 20?
    - Why riskier as it goes?
      - Get gambler's fallacy, but rebound if make it longer
      - "come up heads" will be tails
      - But no feedback. Still trying to even things out
      - Haven't been choosing them, better start choosing them
      - Law of small numbers
      - Give people enough trials: will choose risky option
    - Why not risky things early?
      - Probably risk aversion
    - Important implication
      - Could be big deal
      - If you were looking at gambles and giving feedback
      - People are losing
      - In become riskier
      - Expect to choose riskier things
      - A lot of experiments like that tell people how many rounds there
      - Need to check
      - But we're seeing it without losses
      - Period effect?
    - Hot hand
      - U shaped
      - People think sequence will continue, then against it, then rebound back
        up
      - "Rebound effect"
      - Related to WMC
      - Shifted when you have more capacity
    - Not taking into account shape
    - Similarity effect
      - There are people who see the low as different
      - once you bracket for them they prefer them to be different
**** TODO Action #4 Aggregation experiments summary                      :#4:
*** Analogy
    - Maybe we need more data to address
    - Maybe honours student can follow up
* Notes from <2020-11-10 Tue>                                       :ARCHIVE:
** Present at meeting
   - [X] Micah
** Notes
   - Break down into different effects
   - care about the different effect
   - What effects?
     - explicit: 80
   - Something crazy
     - What if what
     - High null effect BF for alignment in implicit condition
     - Or equivalence
     - Interaction lets you infer
   - total
     - two three-ways
     - one two-way
   - four way only makes sense with other ones
   - if we get
   - Markers
     - Jeff lowenstein
     - Guy who worked with
     - can be strategic about it and get someone to force to read the work
*** TODO Action #6 Check about HDR funds                                 :#6:
*** TODO Action #7 Ask Dan if he can answer Rob's question               :#7:
*** TODO Action #8 Run specific power analyses                           :#8:
    - explict vs implicit (three-way) - high alignment
    - explict vs implicit (two-way) - low alignment
    - high vs low alignment (three-way) - explicit reliability
    - implicit null effects
* Notes from <2020-11-23 Mon>                                       :ARCHIVE:
** Present at meeting
   - [X] Evan Livesey
   - [X] Daniel Costa
** Agenda
   - Annual Progress Review interview
** Notes
   - Covid impact
   - Document impact
   - Tight timeframe
   - Writing motivation varies
   - Not just writing quickly
   - Also feedback
   - Expectations of things to read
   - Consider how important it is to get feedback from everyone
   - "planning on finalising by this date"
   - Team is receptive if impose a deadline
   - Covid
   - If you need a further extension need to document
   - Working environment
   - Potentially extend again
   - Won't be an issue to ask for more time
*** TODO Action #9 Work out plan of when to get drafts back to me        :#9:
* Notes from <2020-11-30 Mon>                                       :ARCHIVE:
** Present at meeting
   - [X] Dan
** Agenda
   - Alignment 8
   - RA and McKinsey payments
** Notes
   - page 2: 400-900 too large?
     - when NPV is higher should have a higher range
     - so it's not dominated
   - page 3:
     - not saying shift to npv, just rely less
     - Just a comment
   - Money:
     - Managers:
       - assuming $30 per person, 13 x 448 = 13,440
     - a lot but we can do it
   - Add "The projects are not correlated"
     - "Each project is indepdent of the others"
   - Why "predicted" project features
     - all good
   - Do we want a limit on allocation per project?
     - Are we getting enough
     - should have minimum allocation for each
   - Figure 7: what's different from previous
   - Should we go to three?
   - should we have payoffs
     - play these things out
     - yes
   - let dan try out experiment
   - table to describe differences
   - values
     - showing the rate is bigger
   - might submit to management science
     - or smj (easier on this)
   - when give the range
     - somehwhere early: say range is uniform distribution
   - whenever there's a dominant choices, e.g. high EV and non overlapping
     range
   - Cap on wednesday
*** TODO Action #10 add uniform distribution                            :#10:
    CLOSED: [2020-12-01 Tue 08:59]
*** TODO Action #11 add "Each project is indepdent of the others"       :#11:
    CLOSED: [2020-12-01 Tue 08:55]
*** TODO Action #12 send Dan experiment link                            :#12:
    CLOSED: [2020-12-01 Tue 21:38]
    - State "TODO"       from              [2020-11-30 Mon 19:30]
*** TODO Action #13 Wednesday cap on McKinsey and RA payments           :#13:
    CLOSED: [2020-12-07 Mon 09:31]
    - State "DONE"       from "TODO"       [2020-12-07 Mon 09:31]
    - State "TODO"       from              [2020-11-30 Mon 19:30]
* Notes from <2020-12-07 Mon>                                       :ARCHIVE:
** Present at meeting
   - [ ] Dan
   - [X] Micah
   - [X] Bruce
** Agenda
   - Anecdotes 1
   - Anecdotes 2
** Notes
*** Rob comment                                                         :#16:
    - Rob was saying that global similarity is still not necessarily a bad thing,
      even if randomly sample
    - Certainly can diminish
    - Will want an argument
    - Want to minimise other concerns (randomly selected)
    - But also other argument against it
    - Starting with premise that aggregated data is better than cases
    - But need to justify the assumption
    - Medical case: no reason to consider. Because random
    - But here, by manipulating similarity, we are introducing that there are
      high similarity examples
      - So why not go for high similarity.
    - Even if it's random, and it's one of the most similar one in the pool
    - e.g., 
    - Twin: causal relationship and mechanism
      - Same genetics
      - similarity in biology
      - Extreme example
      - May have other factor
    - Need to make argument that ignoring data is normative
    - Make it clear, rather than assuming
**** Case-based literature
     - Shenkin,
     - janet clodner/rodner
     - Saw link between this and analogy
     - wider view of cases
     - didn't always have to be analogy
     - problem with that work: hard to define when it should help and when
       shouldn't
     - empirically test most effective wasn't important
     - illustrates: sometimes people will use anecdotes. not always easy when
       they like to use
     - case based: causal reasoning. when it gave you good causal argument
**** Relative parameters
     - Experiment 1 Ratings: variation about how relevant. relevance were related to
       similarity.
     - Does appear to be causal reasoning
     - One of the reasons why interested: some work where negative anecdote
       affected because causal reasoning, or whether it gives people a negative
       association.
     - Both could be there
       - Even if investment has little relevance, probably does lower investment
     - By manipulating similarity, we might have been making normative case for
       the anecdote
       - Unless we can make the case that the anecdote should be ignored, even
         given this specific detail, then maybe we want to similarity in more
         irrelevant ways.
       - E.g., incompetent manager
     - If we say it failed because number, etc.
       - unless we make it clear that it's not deterministic of failure.
     - Seem to be contrasting anecdotes and data
       - Independent effect of anecdotes and statistics
     - Dan: managers that are seduced by the allure of the case, vs analysis
       - One company that bucked the trend
     - If the statistics are close vs far
       - relative strength which determines the outcome
       - But assumption: people would be overweighing anecdotes
       - But how to define overweighing
*** Connection to base rate neglect                                     :#14:
    - Base rate neglect and representativeness
      - If statistics with neutral case, then 50/50
      - They only use statistics, if had nothing else
      - If you give people a neutral description, then less impact of statistics
        than if by themselves.
    - Can set up situation where there is a clear answer
      - but then it's just extreme, and not the usual grey
    - car reliability
      - Consumer reports: based on 100 000 cases
      - Car X is more reliable than Car Y
      - One friend tells you Car Y is better
      - Anecdote will influence
      - People should be going with statistics
      - But if all you had was 10 cases, limited edition, then maybe the story is relevant
    - Easier to argue when you manipulate variable, have less or than impact
    - Recommendation to managers
      - Fine
    - But teasing apart effect
      - Doesnt need
    - Not always ignore
      - Overweight anecdotes
    - Representativeness heuristic
    - Bob the engineer vs lawyers
      - But: category/essence thing
    - Works as intuition engine
      - Even if it doesn't switch choice, will make you think about it
      - more cautious
      - Normally not a strong effect
    - Medicine
      - Women's health anecdotes affect women more than men
    - Tom Von Leer
      - Studies narratives
      - Social professor of narratology
*** Narratives
    - Work on coherence and reasoning
    - Information presented in coherent way
    - Expect trip advisor stories to have better impact
    - But also could be that the more it's a story the more likely it's a story
      or to this it's real
    - Draws you in
    - Coherence stuff: how much people were effected by coherence across instances?
      - Evaluating political messages: incoherent with other point of view
      - But would people notice?
      - If you're not the expert
      - Paul Thagard was analysing coherence
        - How decision of ship thinking under attack from F15
        - Different bits of information, came to support single story
        - But some ambiguous information was changed to be more coherent
        - So different information can be made to be more coherent
        - "Vincence"?
      - E.g., biden says supporting healthcare but not healthcare for all
*** Analysis                                                            :#15:
    - Can have internal analysis, but then also specific comparison to baseline
    - Not a problem, becaues have no choice
    - Fine to do separate analysis
    - But no specific estimate
    - But DV
    - Could do differnce score?
      - Seems like noisy measure
      - If could get lots of statistics to get baseline
      - But since one can throw things out
      - Needs confidence that they are really the baseline
    - Conceptually works, but might be adding more noise that need
    - If just doing that comparison
      - if statistics compared to high
    - could just do comparison to low sim
    - could do odds ratio terms
      - aggregated across people?
    - Putting in terms of dollar values is specific to experiment
      - The odds of choosing the one that the statistics support is reduced by
        X when high similarity anecdote etc.
    - Could still in prose say that size of effect a is x and effect b is y
    - if you have five groups, and
    - "non fully factorial"
      - But you have a reason why
      - And have hypotheses
*** TODO Action #14 Look into base rate neglect literature              :#14:
    - like car reliability example
*** TODO Action #15 Analyse anecdotes 2 as specific hypotheses          :#15:
    - And infer the interactions
    - So essentially like the stats consultant said
*** TODO Action #16 Clarify that anecdotes are sampled randomly         :#16:
*** TODO Action #17 Justify normative case for aggregated data          :#17:
    - Within our specific parameters
    - e.g., of large number of cases
* Notes from <2020-12-08 Tue>                                       :ARCHIVE:
** Present at meeting
   - [X] Dan
** Agenda
   - Anecdotes 1
   - Anecdotes 2
** Notes
*** Future
    - Send documents as word
    - ARC thing is for colleagues
**** TODO Action #18 Generate word documents when sending PDFs          :#18:
*** rob's comment                                                       :#19:
    - if the other things aren't similar
    - movie study
      - rate similarity of movie to focal movie
      - more weight when similar
    - you can either state that, or that they're all equally similar
    - or third option: list all of the things in the dataset
    - randomly sampled
      - but could be still more similar
      - way around it: say that all of the anecdotes are equally similar to the
    focal case.
    - Not a crazy thing: with reference-class forecasting (kahneman and tversky,
    and dan), each case is counted equally
    - Refined further: different weights on different cases
    - do 1-7 instead of 1-6
**** TODO Action #19 Work out whether to use a six or seven point scale :#19:
     - For anecdotes ratings
*** anecdotes 1                                                         :#20:
    - Rob is right
    - Now understands what he's saying, so not sure what to do
    - If something is more similar, you might have to use it more
    - We've only got two anecdotes
      - In both cases, people pay too much attention to anecdote
    - Do we tell them how many
    - Talk about later today
    - One way to get around it: say something like
      - this example falls within X range, i.e., +- 40-60% percentile
      - Make sure it shouldn't have influence
    - Would be great to have the right weight
      - how much should, if you had similarity ratings of all projects
      - There is a correct weight of how much influence it should have on decision
    - We can also describe the distribution of how similar the projects are
    - And then maybe the randomly choosing
    - If you say it's random distribution, and we define what the highest
    similarity could be. and if the highest similarity isn't .96 but it's .8 then we
    can say that anytihng that's been chosen 
    - instead of cutting off on percentiles. the most similar isn't all that similar.
    - unifrom distribution. experts similarity distribution .3-.8
**** TODO Action #20 Update others with ideas to respond to Rob         :#20:
     - randomly sampled
     - large pool
     - specific company
     - constraining range of possible similarity in the pool
*** ARC                                                                 :#21:
    - look up guideline and for each section a little bit
    - Want to say not findings, but questions
    - Not say thesis
    - improving risky choice in business innovation
    - Powerpoint
    - Names: alphabetical order
    - I have all information
    - presenting in front of people in discipline, and someone from DVC research office
    - can be slide
    - ARC future proposal
**** points to address 
     - Significance
     - listing the different projects and hypotheses
       - like in page 6. study 1 . just the top and three hypotheses
     - national and social benefit: increase risk taking
     - one line on aims and background
****  summary
     - ARC future proposal
     - title: improving risky choice in business innovation
     - Dekel,
     - Aims
       - overcoming inherent risk aversion in organisation decisions
     - if sounds repetitive group
     - ideally on one slide
**** TODO Action #21 Send ARC proposal slides                           :#21:
* Actions
** DONE Action #1 Add explanation for explicit reliability               :#1:
   CLOSED: [2020-11-02 Mon 19:14]
   - But: way I call NPV unreliable
     - the implication of that: unreliable because estimates are imperceise
   - precision of the metric prediction
   - Also:
   #+begin_quote
   I would also change "in this particular industry, NPV is an unrelaible
   predictor of project success" to "in this industry, NPV is an unreliable
   predictor of a project's profits"
   #+end_quote
   - Unreliability
     - Good feature some times too
     - Usually it means that there's a greater upside and downside
     - Makes it sound like a bad thing. Whereas when implicitly unreliable
       might be different
       - Unreliable because it's such a wide range of outcomes
         - broader range = meaning we have less confidence
** DONE Action #2 power analysis                                         :#2:
   CLOSED: [2020-11-19 Thu 11:36]
** DONE Action #3 Send aggregation analyses                              :#3:
   CLOSED: [2020-11-02 Mon 19:14]
   - Thursday - just about aggregation
** CANCELLED Action #4 Aggregation experiments summary                   :#4:
   - State "CANCELLED"  from "TODO"       [2020-12-07 Mon 11:18]
** TODO Action #5 Reanalyse aggregation 4                                :#5:
   - Fix contrasts
   - Try 1 vs 20
   - Try aware vs naive for 20 or last five
   - Try different trends
     - quadratic
     - straight and then linear after half way
** DONE Action #6 Check about HDR funds                                  :#6:
   CLOSED: [2020-11-10 Tue 15:14]
** TODO Action #7 Ask Dan if he can answer Rob's question                :#7:
** DONE Action #8 Run specific power analyses                            :#8:
   CLOSED: [2020-11-19 Thu 11:36]
   - explict vs implicit (three-way) - high alignment
   - explict vs implicit (two-way) - low alignment
   - high vs low alignment (three-way) - explicit reliability
   - implicit null effects
** TODO Action #9 Work out plan of when to get drafts back to me         :#9:
   - Bruce: on leave Christmas - Jan 15
     - And busy rewriting a grant application
** DONE Action #10 add uniform distribution                             :#10:
   CLOSED: [2020-12-01 Tue 08:59]
** DONE Action #11 add "Each project is indepdent of the others"        :#11:
   CLOSED: [2020-12-01 Tue 08:55]
** DONE Action #12 send Dan experiment link                             :#12:
   CLOSED: [2020-12-01 Tue 21:38]
   - State "TODO"       from              [2020-11-30 Mon 19:30]
** DONE Action #13 Wednesday cap on McKinsey and RA payments            :#13:
   CLOSED: [2020-12-07 Mon 09:31]
   - State "DONE"       from "TODO"       [2020-12-07 Mon 09:31]
   - State "TODO"       from              [2020-11-30 Mon 19:30]

** TODO Action #14 Look into base rate neglect literature               :#14:
   - like car reliability example
** TODO Action #15 Analyse anecdotes 2 as specific hypotheses           :#15:
   - And infer the interactions
   - So essentially like the stats consultant said
** TODO Action #16 Clarify that anecdotes are sampled randomly          :#16:
** TODO Action #17 Justify normative case for aggregated data           :#17:
   - Within our specific parameters
   - e.g., of large number of cases

** TODO Action #18 Generate word documents when sending PDFs            :#18:
** TODO Action #19 Work out whether to use a six or seven point scale   :#19:
   - For anecdotes ratings
** TODO Action #20 Update others with ideas to respond to Rob           :#20:
   - randomly sampled
   - large pool
   - specific company
   - constraining range of possible similarity in the pool
** TODO Action #21 Send ARC proposal slides                             :#21:
